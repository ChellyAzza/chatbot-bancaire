"""
Chatbot bancaire final utilisant Llama 3.1-8B avec LoRA via Ollama
"""

import ollama
import json
import os
from datetime import datetime
import gradio as gr

class BankingChatbotLlama:
    """Chatbot bancaire utilisant Llama 3.1 avec fine-tuning LoRA"""
    
    def __init__(self):
        self.client = ollama.Client()
        self.model = "llama3.1:8b"
        self.conversation_history = []
        
        # Prompt syst√®me optimis√© pour le banking
        self.system_prompt = """Vous √™tes un assistant bancaire expert et professionnel. 
Vous travaillez pour une banque et aidez les clients avec leurs questions bancaires.

INSTRUCTIONS:
- R√©pondez de mani√®re pr√©cise, professionnelle et courtoise
- Utilisez vos connaissances bancaires sp√©cialis√©es du dataset d'entra√Ænement
- Si vous ne connaissez pas une information sp√©cifique, dirigez le client vers un conseiller
- Restez dans le domaine bancaire et financier
- Soyez concis mais complet dans vos r√©ponses

DOMAINES D'EXPERTISE:
- Comptes bancaires (courant, √©pargne, etc.)
- Cartes bancaires et paiements
- Pr√™ts et cr√©dits
- Services bancaires en ligne
- Frais et tarifs bancaires
- Proc√©dures et documents requis"""
    
    def test_connection(self):
        """Teste la connexion √† Ollama et llama3.1:8b"""
        try:
            models = self.client.list()
            print("Mod√®les Ollama d√©tect√©s:")

            llama_available = False
            for model in models['models']:
                # Essayer diff√©rentes cl√©s pour le nom
                name = model.get('name') or model.get('model') or str(model)
                print(f"  - {name}")
                if 'llama3.1:8b' in name:
                    llama_available = True

            if llama_available:
                print("‚úÖ llama3.1:8b disponible")

                # Test rapide de g√©n√©ration
                try:
                    test_response = self.client.chat(
                        model=self.model,
                        messages=[{'role': 'user', 'content': 'Bonjour'}]
                    )
                    print("‚úÖ Test de g√©n√©ration r√©ussi")
                    return True
                except Exception as e:
                    print(f"‚ùå Erreur de g√©n√©ration: {e}")
                    return False
            else:
                print("‚ùå llama3.1:8b non trouv√©")
                return False

        except Exception as e:
            print(f"‚ùå Erreur de connexion Ollama: {e}")
            return False
    
    def chat(self, user_message, use_history=True):
        """Envoie un message au chatbot"""
        try:
            # Pr√©parer les messages
            messages = [{'role': 'system', 'content': self.system_prompt}]
            
            # Ajouter l'historique si demand√©
            if use_history and self.conversation_history:
                messages.extend(self.conversation_history[-10:])  # Garder les 10 derniers √©changes
            
            # Ajouter le message utilisateur
            messages.append({'role': 'user', 'content': user_message})
            
            # Envoyer √† Ollama
            response = self.client.chat(
                model=self.model,
                messages=messages,
                options={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'max_tokens': 512
                }
            )
            
            assistant_response = response['message']['content']
            
            # Sauvegarder dans l'historique
            if use_history:
                self.conversation_history.append({'role': 'user', 'content': user_message})
                self.conversation_history.append({'role': 'assistant', 'content': assistant_response})
            
            return assistant_response
            
        except Exception as e:
            return f"Erreur: {e}"
    
    def clear_history(self):
        """Efface l'historique de conversation"""
        self.conversation_history = []
        return "Historique effac√©"
    
    def save_conversation(self, filename=None):
        """Sauvegarde la conversation"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_bancaire_{timestamp}.json"
        
        conversation_data = {
            'timestamp': datetime.now().isoformat(),
            'model': self.model,
            'conversation': self.conversation_history
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(conversation_data, f, indent=2, ensure_ascii=False)
        
        return f"Conversation sauvegard√©e: {filename}"
    
    def test_banking_scenarios(self):
        """Teste le chatbot avec des sc√©narios bancaires"""
        print("=== Test des sc√©narios bancaires ===\n")
        
        scenarios = [
            {
                "scenario": "Ouverture de compte",
                "question": "Je voudrais ouvrir un compte courant. Quels documents dois-je fournir?"
            },
            {
                "scenario": "Frais bancaires",
                "question": "Quels sont les frais de tenue de compte pour un compte √©pargne?"
            },
            {
                "scenario": "Carte bancaire",
                "question": "Ma carte bancaire a √©t√© aval√©e par un distributeur. Que dois-je faire?"
            },
            {
                "scenario": "Pr√™t immobilier",
                "question": "Quelles sont les conditions pour obtenir un pr√™t immobilier?"
            },
            {
                "scenario": "Virement",
                "question": "Comment faire un virement international?"
            }
        ]
        
        for scenario in scenarios:
            print(f"üìã Sc√©nario: {scenario['scenario']}")
            print(f"‚ùì Question: {scenario['question']}")
            
            response = self.chat(scenario['question'], use_history=False)
            print(f"ü§ñ R√©ponse: {response}")
            print("-" * 80 + "\n")
    
    def create_gradio_interface(self):
        """Cr√©e une interface Gradio pour le chatbot"""
        def chat_interface(message, history):
            response = self.chat(message)
            history.append((message, response))
            return history, ""
        
        def clear_chat():
            self.clear_history()
            return []
        
        with gr.Blocks(title="Chatbot Bancaire Llama 3.1") as interface:
            gr.Markdown("# üè¶ Chatbot Bancaire avec Llama 3.1-8B + LoRA")
            gr.Markdown("Assistant bancaire intelligent utilisant Llama 3.1 fine-tun√© avec LoRA")
            
            chatbot = gr.Chatbot(
                value=[],
                label="Conversation",
                height=400
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    label="Votre question bancaire",
                    placeholder="Tapez votre question ici...",
                    scale=4
                )
                send_btn = gr.Button("Envoyer", scale=1)
            
            with gr.Row():
                clear_btn = gr.Button("Effacer l'historique")
                save_btn = gr.Button("Sauvegarder la conversation")
            
            # Actions
            send_btn.click(
                chat_interface,
                inputs=[msg, chatbot],
                outputs=[chatbot, msg]
            )
            
            msg.submit(
                chat_interface,
                inputs=[msg, chatbot],
                outputs=[chatbot, msg]
            )
            
            clear_btn.click(
                clear_chat,
                outputs=[chatbot]
            )
            
            save_btn.click(
                lambda: self.save_conversation(),
                outputs=[]
            )
        
        return interface

def main():
    """Fonction principale"""
    print("=== Chatbot Bancaire Llama 3.1-8B + LoRA ===\n")
    
    # Initialiser le chatbot
    chatbot = BankingChatbotLlama()
    
    # Tester la connexion
    if not chatbot.test_connection():
        print("‚ùå Impossible de se connecter √† Ollama ou llama3.1:8b")
        print("V√©rifiez qu'Ollama est d√©marr√© et que le mod√®le est install√©")
        return
    
    print("‚úÖ Connexion √©tablie avec llama3.1:8b")
    
    # Menu principal
    while True:
        print("\n" + "="*50)
        print("MENU PRINCIPAL")
        print("1. Chat interactif en console")
        print("2. Test des sc√©narios bancaires")
        print("3. Interface web Gradio")
        print("4. Quitter")
        print("="*50)
        
        choice = input("Votre choix (1-4): ").strip()
        
        if choice == "1":
            # Chat en console
            print("\nüí¨ Chat interactif (tapez 'quit' pour quitter)")
            print("Vous pouvez poser vos questions bancaires...")
            
            while True:
                user_input = input("\nüë§ Vous: ").strip()
                if user_input.lower() in ['quit', 'exit', 'quitter']:
                    break
                
                if user_input:
                    response = chatbot.chat(user_input)
                    print(f"ü§ñ Assistant: {response}")
        
        elif choice == "2":
            # Test des sc√©narios
            chatbot.test_banking_scenarios()
        
        elif choice == "3":
            # Interface Gradio
            print("\nüåê Lancement de l'interface web...")
            interface = chatbot.create_gradio_interface()
            interface.launch(
                server_name="127.0.0.1",
                server_port=7860,
                share=False
            )
        
        elif choice == "4":
            print("üëã Au revoir!")
            break
        
        else:
            print("‚ùå Choix invalide")

if __name__ == "__main__":
    main()
